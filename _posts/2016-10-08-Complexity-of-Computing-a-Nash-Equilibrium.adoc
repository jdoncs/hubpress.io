= Complexity of Computing a Nash Equilibrium
:hp-tags Game Theory, Computational Complexity

This is an older paper I've been meaning to read for a couple of years. It's by Christos Papadimitriou (who I've heard of and read before), Paul Goldberg (I think I've read him before), and Constantinos Daskalakis (who I've never heard of). Papadimitriou does a lot of exciting work. The two things that come to my mind are co-inventing https://en.wikipedia.org/wiki/Price_of_anarchy[Price of Anarchy], a metric for the cost of having self-interested (and rational) individuals do as they please, rather than imposing a solution on all of them from some central authority. It's very useful in mechanism design, because it allows us to quantify the improvement in social utility from using a given mechanism, vs. allowing the agents to settle into whatever the usual Nash Equilibrium is for the game of interest. Papadimitriou has also done some work in genetic algorithms, which purports to show that mutation is entirely pointless in evolutionary search. I haven't read the paper on this yet. Perhaps it should be my next review.

== What is this paper about?

In game theory, we study the behaviour of rational agents in various model problems. The classic example is the https://en.wikipedia.org/wiki/Prisoner%27s_dilemma[Prisoner's Dilemma]. Problems in game theory are modelled using the notation of a game. In a game, each actor (player) has a set of possible actions that they could take. Games are played in a single round, where each player picks an action, and an outcome occurs as a function of the joint actions of all the players. For example, in Prisoner's Dilemma, the problem of whether two criminals who have been apprehended should confess their crimes, or stay mum. In this game, each player has the same pair of actions. There are four possible outcomes:

- If both players confess, they both go to jail for a long time (big punishment)
- If one player confesses, and the other stays mum, then the confessing player gets a plea bargin (no punishment), and the one that stayed mum goes to jail for even longer (biggest punishment).
- If both players stay mum, there's only circumstantial evidence against them, so they both to jail on a lessor offense (small punishment).

Usually in game theory, we're interested in figuring out what rational agents would do when confronted with this problem. We can imagine a rational agent in this game to be a computer program that selects actions to minimize its punishment. If two rational agents play this game, we can then reason about what they'll do. The first agent notices that if the other agent stays mum, then their choices are to get a small punishment (by staying mum also), or no punishment at all (plea bargin). So if the other agent is staying mum, then a rational agent should confess. However, if the other player confessess, this agent has a choice between confessing too (big punishment), or staying mum and taking the fall (biggest punishment). Clearly it's better to confess in this case too. Therefore our agent should confess no matter what the other agent does. By identical reasoning, both agents confess, so we can say with confience that two rational agents playing this game will end up in an equilibrium where both of them receive a big punishment.

We might wonder whether there's always an equilibrium of this kind, and it's easy to show that there is not. For example, consider the game Matching Pennies. In this game, each player holds a penny concealed in thier hand. The players can elect to arrange the coin so that either heads or tails will be on top when their palm is openned. The outcome of the game is that if both players reveal the same side of the coin, player 1 gets both pennies. If the players reveal different sides of their coins, player 2 gets them both instead. It should be obvious that deciding to always reveal the same side is a recipe for disaster. An opponent who knows that you're doing this could get a penny from you every time! Despite this, there is still a single right way to play this game. Observe that if a player selects heads or tails uniformly at random (i.e. each of them 50% of the time), then it does not matter what their opponent does: the coins will match as often as not. This type of equilibrium is called a mixed strategy Nash Equilibrium (because each player picks a mixture of the actions as their strategy for playing the game).

Perhaps the biggest result in game theory is Nash's theroem. Nash's theorem shows something rather exciting: every game has at least one mixed strategy Nash equilibrium. This means that the behaviours of rational agents should always be predictable to some degree (there might be more than one equilibrium, so it might not always be clear which one different rational agents will play). Nash's proof shows only the existance of such an equilibrium, but it also gives a method for finding it: if the players each adjust their strategies in turn to exploit whatever their opponents are doing now, then play will eventually converge to an equilibrium. However, the proof does not describe how long players might need to do this before reaching the equilibrium. Nor does it tell us whether there's a faster way to find the equilibrium that avoids this iterative refinement. The main result of this paper by Papadimitriou et al. is to answer these questions. They accomplish this by showing that finding a Nash Equilibrium is at least as hard as some other problems for which no known fast algorithms exist. Surprisingly, these other algorithms are not in NP, as we often expect, but in a more exotic complexity class called PPAD.

=== Complexity

The problem of finding a mixed strategy Nash Equilibrium is known to be easy when the game consists of two players and is zero-sum. When there are more than 2 players, we might wonder how hard it is exactly. Usually computational complexity is expressed (at least, outside of complexity theory conferences and journals) in terms of the two famaliar complexity classes seen in an undergraduate course on algorithms: P and NP. P is the set of problems for which there exists a known algorithm that solves problem instances is a number of operations that is a polynomial function of the input size. For example, if the problem is sorting a list of numbers, the existance of a simple, slow, algorithm like Bubble Sort (which needs a number of operations that is quadratic function of the length of the list) serves to show that the problem of sorting a list of numbers is in P. NP is the set of problems that can be _verrified_ in polynomial time. Verrification consists of taking a problem instance and proposed solution, and checking whether or not the solution is correct. For example, sorting a list of number is in NP because if I give you a list of numbers that are unsorted, and then a list that I claim contains the same numbers in sorted order, you can verrify my claim by simply making sure the two lists contain the same numbers (quadratic time if done naively), and then making sure that the second list is indeed sorted (linear time). It should be obvious that every problem in P is also in NP: we can always run the algorithm in a polynomial number of steps, and see if we get the same solution. However, there exist problems that can be verrified in polynomial time, but for which no polynomial time algorithm is known. An example is something like integer knapsack. The integer knapsack problem consists of being given a bag with a certain total capacity (in liters, say), and a multiset of items of different sizes that are worth different amounts. The question that is asked is whether there exists a way to pack the knapsack such that the total value of the items in it is at least $k$. It should be apparent that brute forcing this is not an option, since the number of subsets that can fit in the bag is going to be exponential. Likewise, it should be obvious that if I present you with a packed bag, it's easy to count up the value of the items in the bag, and see whether that's more than $k$. There's no known deterministic polynomial time algorithm for finding such a packed bag though.

Finding a Nash Equilibrium is clearly in NP: if I give you a proposed equilibrium, you can check whether any player would want to deviate by computing the gradiant of their utility function with respect to the probabilities of playing any given strategy. If the gradiant is zero for every player, we're at an equilibrium. Similarly, we can't be sure whether this problem is in P or not, because we don't have an efficient algorithm for solving it (yet). Usually complexity theorests use this starting point to show that a problem is at least as hard as one of the hardest unsolved problems in NP, called the NP-Complete problems. However, most (all?) NP-Complete problems rely on the fact that a solution might not exist. My understanding is that this is because the fundamental NP-Complete problem is SAT, and other problems are reduced to SAT. The authors of this paper give an arguement that I found a bit handwavy for this. Basically, if we had an efficient way to translate SAT instances (i.e. answering the question of whether or not a particular boolean formula can ever output true), to instances of NASH (Finding an equilibrium where no player can gain more than some fixed amount $\epsilon$ by playing differently), then we could solve SAT instances by _guessing_ a solution to NASH, and checking whether that solution was a solution to SAT or not. The authors say it is easy to show that this could yield a non-deterministic algorithm for solving SAT efficiently, but I'm not sure I see how. Obviously solutiosn will always exist to NASH, since there must be at least one equilibrium with $\epsilon=0$ by Nash's theorem. But would _guessing_ really allow one to find solutions quickly? The authors don't say that an efficient non-deterministic algorithm is needed for NASH, but it seems to me like it must be so.

Anyhow, the point is, complexity theorests have some (inscrutable) reason for thinking that guess and check on NASH would allow efficient non-deterministic solutions to SAT. Therefore they suppose that reductions from SAT to NASH are unlikely to exist. I find this uncompelling, but I'm not a complexity theorest, and I certainly can't find such a reduction myself! If Nash were NP-Complete then by definition, and instance of SAT could be turned into NASH efficiently _somehow_. Therefore, we suppose NASH is probably not NP-Complete.

So NASH is easier than NP-Complete problems (or at least, incomparable with them), but it's in NP, and we don't have any algorithm that would put it in P after about 50 years of trying. A reasonable guess is that NP > NASH > P. As it turns out, there are some other problems that fit this description. Surprisingly, the authors claim (via one of Papadimitriou's other papers) that the set of possible problems that are similar is quite small. We're just looking for problems that have a non-constructive proof that there is always a solution. The non-constructive step turns out to determine similar sets of problems. PPAD is the set of problems where the non-constructive step in the proof is of the form "If a digraph has one node with different numbers of in- and out-edges, then there must be another such node.". The cannonical problem for this class is described as "END-OF-THE-LINE": Given a graph, and a particular vertex with different numbers of in- and out-edges, output some other vertex of the graph that also has different numbers of such edges. Of course, if the graph is provided in a standard format this is a boring (and very simple) problem to solve! Just count the number of edges of each type for every vertex. There are at most $|V|^2$ directed edges, so out work is polynomial. However, END-OF-THE-LINE is proposed to take a rather arcane input format. A graph is represented by two boolean circuits of depth polynomial in the size of the graph. Each circuit takes $k$ inputs and produces $k$ outputs. The graph has $2^k$ vertices, and each is constrained to have at most one in-edge and at most one out-edge. The boolean circuits effectively accept a binary number corresponding to a vertex. One of the circuits outputs the target of the out-edge (if any), and the other outputs the target of the in-edge (if any). Oddly, this appears to constrain the graph to having a unique predecessor for each node, even though it could be the successor of many nodes. Weird. The pathological instance of this problem would be to give a source node as the provided vertex with different numbers of in- and out-edges. We know there must be at least one sink in the graph, but since the structure of the graph is encoded only implicitly, we might need to walk through every vertex to find it (e.g. if the "graph" is really a single linked list). Since we cannot examine the boolean circuits (I guess?), this makes END-OF-THE-LINE hard in the worst case, taking apparently exponential time, even though there's certain to be a solution, and solutions are easy to verify. My complaint about this part of the paper is that END-OF-THE-LINE's encoding seems like a pretty contrived way to represent a graph. I guess it's saying: if you can only observe the local topology of a graph (like if you were trapped in a maze), you might have to check every path to find the exit. But the work is still linear in the size of the graph. It's only exponential in $k$, and $k$ just seems like a contrived notion. Mostly the design seems to be a theoretical contrivence, insofar as some other hard problems with input sizes of $k$ can be reduced to END-OF-THE-LINE with $2^k$ vertices.


== Brouwer's Theorem and PPAD Reductions


Okay. So we have that NASH is an important problem, and that probably $NP > NASH > P$. We also have this weird complexity class PPAD, based around the equally weird problem END-OF-THE-LINE. As one would expect, the meat of the paper is the authors showing that NASH can be converted into END-OF-THE-LINE, and that END-OF-THE-LINE can be converted into NASH. These reductions would establish that NASH is at least as hard as END-OF-THE-LINE, and frankly, END-OF-THE-LINE seems ridiculously hard (assuming we can't examine the boolean circuits, or otherwise infer the graph's structure except by walking around on it). To accomplish this, they rely on Brouwer's fixed point theorem, which is what's used in the core non-constructive step of Nash's theorem.

Brouwer's fixed point theorem says that if you map any "reasonable" subset of a Euclidian space to a "reasonable" subspace of itself, there's at least one point that doesn't move (i.e. the "fixed" point). Here, "reasonable" means that it's a contiguous proper sub-region of the space. So the unit ball is good (for any number of dimensions), but something like two disjoint balls isn't. If you think about this for a minute, it seems true, though if I think about it for more than a minute I always come up with some weird mapping that seems like it doesn't have a fixed point. Later I always figure out what the fixed point is though. Nash's theorem relies on this notion. The space is the set of probabilities that each player uses to decide which strategy to play. This ends up being some sort of scaling of the unit ball for a high dimesional space, since the probabilities for each player need to sum to 1 (so we should get a ball with radius $n$, for $n$ players. Suppose that players adjust their strategies to improve utility, given the strategies of their opponents. Then each of these points has a sucessor point, the strategy profile that the players would move to if they started here. The mapping from points to successors is "reasonable", so by Brouwer's theorem, there's a fixed point, a point where the players don't want to move, which must be a Nash equilibrium.

The authors propose the computational search problem BROUWER, which takes the unit hyper-cube with $m$ dimensions, and a polynomial-time computable mapping $F$ from points in the cube $x$ to other points in the cube $F(x)$, and produces a fixed point of the mapping. They do this $\epsilon$-approximate fixed point thing again, apparently because algorithms don't do irrational numbers (makes sense: we'd be "computing" forever just to write down an irrational fixed point). They also require that $F$ obeys a Lipschitz condition: i.e. if two points $x$ and $y$ are a distance $d$ apart, then $F(x)$ and $F(y)$ are no more than $K\times d$ apart for some constant $K$.

To show that BROUWER maps to END-OF-THE-LINE, the authors propose the following technique:

1. Put down a lattice of points over the hypercube, such that the  diagonal distance between any two points in the lattice is never more than twice $\epsilon$. That is, every point in the hypercube is within a distance $\epsilon$ of one of the lattice points. Strangly, this step is exponential in $\epsilon$ and $m$. The authors don't comment on this at all.
2. For every point in the lattice $x$, compute $F(x)$, which is an efficient operation. 
3. Divide the unit ball of dimension $m$ into three contiguous regions, and color them red, blue and yellow.
4. Compute the direction of the vector $F(x) - x$, and map that vector onto the unit ball. Color lattice point $x$ based on the corresponding color from step 3.
5. Define a mesh of triangular prisims over the lattice, of equal size.
6. 








https://people.csail.mit.edu/costis/simplified.pdf[Paper Here]