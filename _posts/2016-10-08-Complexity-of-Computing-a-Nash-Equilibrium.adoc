= Complexity of Computing a Nash Equilibrium
:hp-tags Game Theory, Computational Complexity

This is an older paper I've been meaning to read for a couple of years. It's by Christos Papadimitriou (who I've heard of and read before), Paul Goldberg (I think I've read him before), and Constantinos Daskalakis (who I've never heard of). Papadimitriou does a lot of exciting work. The two things that come to my mind are co-inventing https://en.wikipedia.org/wiki/Price_of_anarchy[Price of Anarchy], a metric for the cost of having self-interested (and rational) individuals do as they please, rather than imposing a solution on all of them from some central authority. It's very useful in mechanism design, because it allows us to quantify the improvement in social utility from using a given mechanism, vs. allowing the agents to settle into whatever the usual Nash Equilibrium is for the game of interest. Papadimitriou has also done some work in genetic algorithms, which purports to show that mutation is entirely pointless in evolutionary search. I haven't read the paper on this yet. Perhaps it should be my next review.

== What is this paper about?

In game theory, we study the behaviour of rational agents in various model problems. The classic example is the https://en.wikipedia.org/wiki/Prisoner%27s_dilemma[Prisoner's Dilemma]. Problems in game theory are modelled using the notation of a game. In a game, each actor (player) has a set of possible actions that they could take. Games are played in a single round, where each player picks an action, and an outcome occurs as a function of the joint actions of all the players. For example, in Prisoner's Dilemma, the problem of whether two criminals who have been apprehended should confess their crimes, or stay mum. In this game, each player has the same pair of actions. There are four possible outcomes:

- If both players confess, they both go to jail for a long time (big punishment)
- If one player confesses, and the other stays mum, then the confessing player gets a plea bargin (no punishment), and the one that stayed mum goes to jail for even longer (biggest punishment).
- If both players stay mum, there's only circumstantial evidence against them, so they both to jail on a lessor offense (small punishment).

Usually in game theory, we're interested in figuring out what rational agents would do when confronted with this problem. We can imagine a rational agent in this game to be a computer program that selects actions to minimize its punishment. If two rational agents play this game, we can then reason about what they'll do. The first agent notices that if the other agent stays mum, then their choices are to get a small punishment (by staying mum also), or no punishment at all (plea bargin). So if the other agent is staying mum, then a rational agent should confess. However, if the other player confessess, this agent has a choice between confessing too (big punishment), or staying mum and taking the fall (biggest punishment). Clearly it's better to confess in this case too. Therefore our agent should confess no matter what the other agent does. By identical reasoning, both agents confess, so we can say with confience that two rational agents playing this game will end up in an equilibrium where both of them receive a big punishment.

We might wonder whether there's always an equilibrium of this kind, and it's easy to show that there is not. For example, consider the game Matching Pennies. In this game, each player holds a penny concealed in thier hand. The players can elect to arrange the coin so that either heads or tails will be on top when their palm is openned. The outcome of the game is that if both players reveal the same side of the coin, player 1 gets both pennies. If the players reveal different sides of their coins, player 2 gets them both instead. It should be obvious that deciding to always reveal the same side is a recipe for disaster. An opponent who knows that you're doing this could get a penny from you every time! Despite this, there is still a single right way to play this game. Observe that if a player selects heads or tails uniformly at random (i.e. each of them 50% of the time), then it does not matter what their opponent does: the coins will match as often as not. This type of equilibrium is called a mixed strategy Nash Equilibrium (because each player picks a mixture of the actions as their strategy for playing the game).

Perhaps the biggest result in game theory is Nash's theroem. Nash's theorem shows something rather exciting: every game has at least one mixed strategy Nash equilibrium. This means that the behaviours of rational agents should always be predictable to some degree (there might be more than one equilibrium, so it might not always be clear which one different rational agents will play). Nash's proof shows only the existance of such an equilibrium, but it also gives a method for finding it: if the players each adjust their strategies in turn to exploit whatever their opponents are doing now, then play will eventually converge to an equilibrium. However, the proof does not describe how long players might need to do this before reaching the equilibrium. Nor does it tell us whether there's a faster way to find the equilibrium that avoids this iterative refinement. The main result of this paper by Papadimitriou et al. is to answer these questions. They accomplish this by showing that finding a Nash Equilibrium is at least as hard as some other problems for which no known fast algorithms exist. Surprisingly, these other algorithms are not in NP, as we often expect, but in a more exotic complexity class called PPAD.

=== Complexity

The problem of finding a mixed strategy Nash Equilibrium is known to be easy when the game consists of two players and is zero-sum. When there are more than 2 players, we might wonder how hard it is exactly. Usually computational complexity is expressed (at least, outside of complexity theory conferences and journals) in terms of the two famaliar complexity classes seen in an undergraduate course on algorithms: P and NP. P is the set of problems for which there exists a known algorithm that solves problem instances is a number of operations that is a polynomial function of the input size. For example, if the problem is sorting a list of numbers, the existance of a simple, slow, algorithm like Bubble Sort (which needs a number of operations that is quadratic function of the length of the list) serves to show that the problem of sorting a list of numbers is in P. NP is the set of problems that can be _verrified_ in polynomial time. Verrification consists of taking a problem instance and proposed solution, and checking whether or not the solution is correct. For example, sorting a list of number is in NP because if I give you a list of numbers that are unsorted, and then a list that I claim contains the same numbers in sorted order, you can verrify my claim by simply making sure the two lists contain the same numbers (quadratic time if done naively), and then making sure that the second list is indeed sorted (linear time). It should be obvious that every problem in P is also in NP: we can always run the algorithm in a polynomial number of steps, and see if we get the same solution. However, there exist problems that can be verrified in polynomial time, but for which no polynomial time algorithm is known. An example is something like integer knapsack. The integer knapsack problem consists of being given a bag with a certain total capacity (in liters, say), and a multiset of items of different sizes that are worth different amounts. The question that is asked is whether there exists a way to pack the knapsack such that the total value of the items in it is at least $k$. It should be apparent that brute forcing this is not an option, since the number of subsets that can fit in the bag is going to be exponential. Likewise, it should be obvious that if I present you with a packed bag, it's easy to count up the value of the items in the bag, and see whether that's more than $k$. There's no known deterministic polynomial time algorithm for finding such a packed bag though.

Finding a Nash Equilibrium is clearly in NP: if I give you a proposed equilibrium, you can check whether any player would want to deviate by computing the gradiant of their utility function with respect to the probabilities of playing any given strategy. If the gradiant is zero for every player, we're at an equilibrium. Similarly, we can't be sure whether this problem is in P or not, because we don't have an efficient algorithm for solving it (yet). Usually complexity theorests use this starting point to show that a problem is at least as hard as one of the hardest unsolved problems in NP, called the NP-Complete problems. However, most (all?) NP-Complete problems rely on the fact that a solution might not exist. My understanding is that this is because the fundamental NP-Complete problem is SAT, and other problems are reduced to SAT. The authors of this paper give an arguement that I found a bit handwavy for this. Basically, if we had an efficient way to translate SAT instances (i.e. answering the question of whether or not a particular boolean formula can ever output true), to instances of NASH (Finding an equilibrium where no player can gain more than some fixed amount $\epsilon$ by playing differently), then we could solve SAT instances by _guessing_ a solution to NASH, and checking whether that solution was a solution to SAT or not. The authors say it is easy to show that this could yield a non-deterministic algorithm for solving SAT efficiently, but I'm not sure I see how. Obviously solutiosn will always exist to NASH, since there must be at least one equilibrium with $\epsilon=0$ by Nash's theorem. But would _guessing_ really allow one to find solutions quickly? The authors don't say that an efficient non-deterministic algorithm is needed for NASH, but it seems to me like it must be so.

Anyhow, the point is, complexity theorests have some (inscrutable) reason for thinking that guess and check on NASH would allow efficient non-deterministic solutions to SAT. Therefore they suppose that reductions from SAT to NASH are unlikely to exist. I find this uncompelling, but I'm not a complexity theorest, and I certainly can't find such a reduction myself! If Nash were NP-Complete then by definition, and instance of SAT could be turned into NASH efficiently _somehow_. Therefore, we suppose NASH is probably not NP-Complete.

So NASH is easier than NP-Complete problems (or at least, incomparable with them), but it's in NP, and we don't have any algorithm that would put it in P after about 50 years of trying. A reasonable guess is that NP > NASH > P. As it turns out, there are some other problems that fit this description. 





https://people.csail.mit.edu/costis/simplified.pdf[Paper Here]